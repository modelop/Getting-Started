{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>An ELMo/XGBoost Model for Text Classification</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching  & Processing the '20newsgroups' Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). Let's extract and process a training set correponding to two categories: *'alt.atheism'* and *'sci.space'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import csv\n",
    "import re  # RegEx\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space']  # Extracting two specific categories\n",
    "label, cnt = 0, 0\n",
    "\n",
    "with open(\"train.csv\", \"w\", newline = '') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['id', 'comment_text', 'label'])  # Each comment will have an ID and a label ('0' or '1')\n",
    "    \n",
    "    for cat in categories:\n",
    "        train = fetch_20newsgroups(subset = 'train', categories =[cat], remove = ('headers', 'footers', 'quotes'))\n",
    "        \n",
    "        for n in range(len(train.data)):\n",
    "            \n",
    "            comment = train.data[n].replace('\\n', \" \")\n",
    "            # Remove URLs from train and test\n",
    "            comment = re.sub(r'http\\S+', '', comment)\n",
    "            # Remove punctuation marks\n",
    "            punctuation = '!\"#$%&()*+-/,:;<=>?@[\\\\]^_`{|}~'\n",
    "            comment = ''.join(ch for ch in comment if ch not in set(punctuation))\n",
    "            # Convert text to lowercase\n",
    "            comment = comment.lower()\n",
    "            # Remove numbers\n",
    "            comment = re.sub(r'[0-9]+', '', comment)\n",
    "            # Remove whitespaces\n",
    "            comment = ' '.join(comment.split())\n",
    "\n",
    "            if len(comment) < 1000 and len(comment) > 25:  # Discarding very short comments\n",
    "                row = [str(cnt), comment, str(label)]\n",
    "                w.writerow(row)\n",
    "                cnt += 1\n",
    "            elif len(comment) >= 1000:\n",
    "                row = [str(cnt), comment[0:1000], str(label)]  # Limiting large comments to 1000 characters\n",
    "                w.writerow(row)\n",
    "                cnt += 1\n",
    "        label += 1  # Changing the label for the next category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample row (last row) from the *.csv* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1035', \"many of you at this point have seen a copy of the lunar resources data purchase act by now. this bill also known as the back to the moon bill would authorize the u.s. government to purchase lunar science data from private and nonprofit vendors selected on the basis of competitive bidding with an aggregate cap on bid awards of million. if you have a copy of the bill and can't or don't want to go through all of the legalese contained in all federal legislationdon't both you have a free resource to evaluate the bill for you. your local congressional office listed in the phone bookis staffed by people who can forward a copy of the bill to legal experts. simply ask them to do so and to consider supporting the lunar resources data purchase act. if you do get feedback negative or positive from your congressional office please forward it to david anderman e. yorba linda blvd. apt g fullerton ca or via email to david.andermanofa.fidonet.org. another resource is your local chapter of the nationa\", '1']\n"
     ]
    }
   ],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now write a corresponding *.json* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "# Open the CSV\n",
    "f = open('train.csv', 'r')\n",
    "f.seek(0)\n",
    "next(f)\n",
    "reader = csv.DictReader(f, fieldnames = ('id', 'comment_text', 'label'))  \n",
    "\n",
    "# Parse the CSV into JSON  \n",
    "out = json.dumps([ row for row in reader ])  \n",
    "\n",
    "# Save the JSON  \n",
    "f = open('train.json', 'w')\n",
    "f.write(out)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing ELMo Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the ELMo vectors of our training data. Let's begin by loading the training data as a *Pandas* DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At data loading, train is of shape  (1036, 3)  and of type  <class 'pandas.core.frame.DataFrame'>\n",
      "At data loading, train['comment_text'] is of type  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppressing some TensorFlow warnings.\n",
    "\n",
    "from math import floor\n",
    "\n",
    "# Read data\n",
    "train = pd.read_json(\"train.json\", orient = \"records\")\n",
    "\n",
    "print(\"At data loading, train is of shape \", train.shape, \" and of type \", type(train))\n",
    "print(\"At data loading, train['comment_text'] is of type \", type(train['comment_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few of examples in the DataFrame *train*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text  id  label\n",
      "0  ideologies also split giving more to disagree ...   0      0\n",
      "1  i would rather be at a higher risk of being ki...   1      0\n",
      "2  nope germany has extremely restrictive citizen...   2      0\n"
     ]
    }
   ],
   "source": [
    "print(train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load a *spaCy* language model, as well as a trainable ELMo model from *TensorFlow Hub*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 14:12:18.857589  9884 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm  # spaCy's English model. To install: $ python -m spacy download en_core_web_sm\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load spaCy's language model\n",
    "nlp = en_core_web_sm.load(disable = ['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts):\n",
    "    \"\"\"A function to lemmatize texts\"\"\"\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "train['comment_text'] = lemmatization(train['comment_text'])\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    \"\"\"A function to compute ELMo embeddings\"\"\"\n",
    "    embeddings = elmo(x.tolist(), signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        #  return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of elmo:  <class 'tensorflow_hub.module.Module'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of elmo: \", type(elmo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to extract ELMo vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_samples = 1 # Set to 1 to train on all of input dataset\n",
    "\n",
    "batch_size = 50\n",
    "    \n",
    "list_train = [train[i:i+batch_size] for i in range(0, floor(percent_samples*train.shape[0]), batch_size)]\n",
    "\n",
    "# Extract ELMo embeddings - Uncomment the two lines below to compute from scratch; \n",
    "# otherwise, load from .pickle file\n",
    "#elmo_train = [elmo_vectors(x['comment_text']) for x in list_train]\n",
    "#elmo_train = np.concatenate(elmo_train, axis = 0)\n",
    "elmo_train = pickle.load(open(\"elmo_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ELMo vectors took a long time to compute. Let's save them in a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save elmo_train\n",
    "pickle_out = open(\"elmo_train.pickle\", \"wb\")\n",
    "pickle.dump(elmo_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo_train is of type:  <class 'numpy.ndarray'> , and of shape:  (1036, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(\"elmo_train is of type: \", type(elmo_train), \", and of shape: \", elmo_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load trained ELMo embeddings from elmo_train.pickle\n",
    "pickle_in = open(\"elmo_train.pickle\", \"rb\")\n",
    "elmo_train_loaded = pickle.load(pickle_in)\n",
    "\n",
    "# Load raw training data to extract labels\n",
    "train = pd.read_json(\"train.json\", orient = \"records\")\n",
    "y_train = train['label']\n",
    "\n",
    "temp = np.array(y_train)\n",
    "y_train = temp.astype(np.int) # Converting labels in y_train to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Setup and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start tuning the maximum depth of the trees first, along with the min_child_weight. We set the objective to *‘binary:logistic’* since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [1, 3, 5], 'min_child_weight': [1, 3, 5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                             cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s run our grid search with 5-fold cross-validation and see which parameters perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=0.8, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=1000, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=0, silent=None,\n",
       "                                     subsample=0.8, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [1, 3, 5], 'min_child_weight': [1, 3, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.fit(elmo_train_loaded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our best score and best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131274131274131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out what were the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'min_child_weight': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try optimizing some other hyperparameters now to see if we can beat a mean of 91.31% accuracy. This time, we will play around with subsampling along with lowering the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7, 0.8, 0.9]}\n",
    "ind_params = {'n_estimators': 1000, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 1, 'min_child_weight': 3}\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=0.8, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=1, min_child_weight=3,\n",
       "                                     missing=None, n_estimators=1000, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=0, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.01],\n",
       "                         'subsample': [0.7, 0.8, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.fit(elmo_train_loaded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our score and parameters again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131274131274131"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that subsampling and learning rates were optimized already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'subsample': 0.8}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the CV testing performed earlier, we want to utilize the following parameters:\n",
    "\n",
    "-  learning_rate = 0.1\n",
    "-  Subsample = 0.8\n",
    "-  Max_depth = 1\n",
    "-  Min_child_weight = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the performance of *XGBoost*’s speed through many iterations of the training set, and since we are using only *XGBoost*’s API and not *sklearn*’s anymore, we can create a *DMatrix*. This sorts the data initially to optimize for *XGBoost* when it builds trees, making the algorithm more efficient. This is especially helpful when you have a very large number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(elmo_train_loaded, y_train) # Creating a DMatrix to make XGBoost more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s specify our parameters and set our stopping criteria. For now, let’s be aggressive with the stopping and say we don’t want the accuracy to improve for at least 100 new trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb optimal parameters\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':1, 'min_child_weight':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'],\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at our CV results to see how accurate we were with these settings. The output is automatically saved into a pandas dataframe for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.084954</td>\n",
       "      <td>0.012887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.083027</td>\n",
       "      <td>0.014848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.083993</td>\n",
       "      <td>0.011766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.084959</td>\n",
       "      <td>0.012539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.083027</td>\n",
       "      <td>0.012824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "444          0.000241         0.000482         0.084954        0.012887\n",
       "445          0.000241         0.000482         0.083027        0.014848\n",
       "446          0.000241         0.000482         0.083993        0.011766\n",
       "447          0.000241         0.000482         0.084959        0.012539\n",
       "448          0.000241         0.000482         0.083027        0.012824"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best iteration: 448. Our CV test error at this number of iterations is 8.3%, or 91.7% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our best settings, let’s create this as an *XGBoost* object model that we can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':1, 'min_child_weight':3}\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now save the trained model as a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_gb,open(\"ELMO_nlp_xgboost.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Performance on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct a test dataset to analyze the performance of our trained model, and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re  # RegEx\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space']  # Extracting two specific categories\n",
    "label, cnt = 0, 0\n",
    "\n",
    "with open(\"ELMo_input_data.csv\", \"w\", newline='') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['id', 'comment_text', 'label'])  # Each comment will have an ID and a label ('0' or '1')\n",
    "    \n",
    "    for cat in categories:\n",
    "        test = fetch_20newsgroups(subset = 'test', categories = [cat], remove = ('headers', 'footers', 'quotes'))\n",
    "        \n",
    "        for n in range(len(test.data)):            \n",
    "            \n",
    "            comment = test.data[n].replace('\\n', \" \")            \n",
    "            # Remove URL's from train and test\n",
    "            comment = re.sub(r'http\\S+', '', comment)\n",
    "            # Remove punctuation marks\n",
    "            punctuation = '!\"#$%&()*+-/,:;<=>?@[\\\\]^_`{|}~'\n",
    "            comment = ''.join(ch for ch in comment if ch not in set(punctuation))\n",
    "            # Convert text to lowercase\n",
    "            comment = comment.lower()\n",
    "            # Remove numbers\n",
    "            comment = re.sub(r'[0-9]+', '', comment)\n",
    "            # Remove whitespaces\n",
    "            comment = ' '.join(comment.split())\n",
    "\n",
    "            if len(comment) < 1000 and len(comment) > 25:  # Discarding very short comments\n",
    "                row = [str(cnt), comment, str(label)]\n",
    "                w.writerow(row)\n",
    "                cnt += 1\n",
    "            elif len(comment) >= 1000:\n",
    "                row = [str(cnt), comment[0:1000], str(label)]  # Limiting large comments to 1000 characters\n",
    "                w.writerow(row)\n",
    "                cnt += 1\n",
    "        label += 1  # Changing the label for the next category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "# Open the CSV\n",
    "f = open('ELMo_input_data.csv', 'r')\n",
    "f.seek(0)\n",
    "next(f)\n",
    "reader = csv.DictReader(f, fieldnames = ('id', 'comment_text', 'label'))  \n",
    "# Parse the CSV into JSON  \n",
    "out = json.dumps([ row for row in reader ])  \n",
    "\n",
    "# Save the JSON  \n",
    "f = open('ELMo_input_data.json', 'w')  \n",
    "f.write(out)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text  id  label\n",
      "0  some big deletions another in a string of idio...   0      0\n",
      "1  you should wear your nicest boxer shorts and b...   1      0\n",
      "Test data is of shape:  (685, 3)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_json('ELMo_input_data.json', orient = 'records')\n",
    "print(test.head(2))\n",
    "print(\"Test data is of shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate ELMo vectors for test data, and save them in a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['comment_text'] = lemmatization(test['comment_text'])\n",
    "\n",
    "percent_samples = 1  # set to 1 to score all of test dataset  \n",
    "batch_size = 50\n",
    "list_test = [test[i:i+batch_size] for i in range(0,floor(percent_samples*test.shape[0]),batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract ELMo embeddings - Uncomment the two lines below to compute from scartch; \n",
    "# otherwise, load from .pcikle file\n",
    "#elmo_vecs = [elmo_vectors(x['comment_text']) for x in list_test]\n",
    "#elmo_vecs = np.concatenate(elmo_vecs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_vecs = pickle.load(open(\"elmo_test.pickle\", \"rb\"))  # Loading saved elmo_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save elmo_vecs\n",
    "pickle_out = open(\"elmo_test.pickle\",\"wb\")\n",
    "pickle.dump(elmo_vecs, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the trained XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"ELMO_nlp_xgboost.pickle\",\"rb\"))  # Loading saved xgboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate predictions on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(xgb.DMatrix(elmo_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions) # Uncomment to view predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use sklearn’s accuracy metric to see how well we did on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function for *XGBoost* outputs probabilities by default and not actual class labels. To calculate accuracy we need to convert these to a 0/1 label. We will set 0.5 probability as our threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  86.28 %\n"
     ]
    }
   ],
   "source": [
    "y_test = test['label']\n",
    "temp = np.array(y_test)\n",
    "y_test = temp.astype(np.int) # Converting y_train to integers\n",
    "\n",
    "print(\"Accuracy on test data: \", round(100*accuracy_score(predictions, y_test),2),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
