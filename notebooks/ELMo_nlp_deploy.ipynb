{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching & Processing the '20newsgroups' Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). Let's extract and process a training set correponding to two categories: *'alt.atheism'* and *'sci.space'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space'] # Extracting two specific categories\n",
    "idx=0\n",
    "cnt=0\n",
    "with open(\"train.csv\",\"w\",newline='') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['id','comment_text','label']) # each comment will have an id and a label ('0' or '1')\n",
    "    \n",
    "    for cat in categories:\n",
    "        train= fetch_20newsgroups(subset='train', categories=[cat], remove=('headers', 'footers', 'quotes'))\n",
    "        \n",
    "        for n in range(len(train.data)):\n",
    "            \n",
    "            comment = train.data[n].replace('\\n',\" \")\n",
    "            \n",
    "            # remove URL's from train and test\n",
    "            comment = re.sub(r'http\\S+', '', comment)\n",
    "\n",
    "            # remove punctuation marks\n",
    "            punctuation = '!\"#$%&()*+-/,:;<=>?@[\\\\]^_`{|}~'\n",
    "            comment = ''.join(ch for ch in comment if ch not in set(punctuation))\n",
    "\n",
    "            # convert text to lowercase\n",
    "            comment = comment.lower()\n",
    "\n",
    "            # remove numbers\n",
    "            comment = re.sub(r'[0-9]+', '', comment)\n",
    "\n",
    "            # remove whitespaces\n",
    "            comment = ' '.join(comment.split())\n",
    "\n",
    "            if len(comment)<2000 and len(comment)>25: # discarding very short comments and very large comments\n",
    "                cnt=cnt+1\n",
    "                row = [str(cnt), comment, str(idx)]\n",
    "                w.writerow(row)\n",
    "        idx=idx+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample row (last row) from the .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now write a corresponding *.json* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "# Open the CSV\n",
    "f = open('train.csv', 'r')\n",
    "reader = csv.DictReader(f, fieldnames = ('id','comment_text','label'))  \n",
    "# Parse the CSV into JSON  \n",
    "out = json.dumps([ row for row in reader ])  \n",
    "\n",
    "# Save the JSON  \n",
    "f = open('train.json', 'w')  \n",
    "f.write(out)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing ELMo Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the ELMo vectors of our training data. Let's begin by loading the training data as a *Pandas* DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from math import floor\n",
    "\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "#read data\n",
    "train = pd.read_json(\"train.json\",orient=\"records\")\n",
    "train = train.iloc[1:] #First record is a repetition of labels - skipping it\n",
    "\n",
    "print(\"\\nAt data loading, train is of shape \", train.shape, \" and of type \", type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple of examples in the DataFrame *train*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load a *spaCy* language model, as well as a trainable *ELMo* model from *tensorflow_hub*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm # to install: $ python -m spacy download en_core_web_sm\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Supressing some TensorFlow warnings. Comment this line to display warnings\n",
    "\n",
    "# load spaCy's language model\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "train['comment_text'] = lemmatization(train['comment_text'])\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to extract *ELMo* vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_samples = 1 # set to 1 to train all of input dataset, .5 to train half, etc.\n",
    "\n",
    "batch_size = 50\n",
    "    \n",
    "list_train = [train[i:i+batch_size] for i in range(0,floor(percent_samples*train.shape[0]),batch_size)]\n",
    "\n",
    "# Extract ELMo embeddings - Uncomment the two lines below to compute from scratch; otherwise, load from .pickle file\n",
    "elmo_train = [elmo_vectors(x['comment_text']) for x in list_train]\n",
    "elmo_train = np.concatenate(elmo_train, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *ELMo* vectors took a long time to compute. Let's save them in a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save elmo_train\n",
    "pickle_out = open(\"elmo_train.pickle\",\"wb\")\n",
    "pickle.dump(elmo_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"elmo_train is of type: \", type(elmo_train), \", and of shape: \", elmo_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load elmo_train\n",
    "pickle_in = open(\"elmo_train.pickle\", \"rb\")\n",
    "elmo_train_loaded = pickle.load(pickle_in)\n",
    "\n",
    "#load raw training data to extract labels\n",
    "train = pd.read_json(\"train.json\",orient=\"records\")\n",
    "train = train.iloc[1:]\n",
    "y_train = train['label']\n",
    "\n",
    "temp = np.array(y_train)\n",
    "y_train = temp.astype(np.int) # converting y_train to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Setup and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start tuning the *maximum depth* of the trees first, along with the *min_child_weight*. We set the objective to *‘binary:logistic’* since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s run our grid search with 5-fold cross-validation and see which parameters perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(elmo_train_loaded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our best score and best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try optimizing some other hyperparameters now to see if we can beat a mean of XX.YY% accuracy. This time, we will play around with subsampling along with lowering the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9]}\n",
    "ind_params = {'n_estimators': 1000, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 5, 'min_child_weight': 3}\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(elmo_train_loaded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our score and parameters again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the CV testing performed earlier, we want to utilize the following parameters:\n",
    "\n",
    "* learning_rate = 0.1\n",
    "* Subsample = 0.8\n",
    "* Max_depth = 5\n",
    "* Min_child_weight = 3\n",
    "\n",
    "To increase the performance of *XGBoost*’s speed through many iterations of the training set, and since we are using only *XGBoost*’s API and not *sklearn*’s anymore, we can create a *DMatrix*. This sorts the data initially to optimize for *XGBoost* when it builds trees, making the algorithm more efficient. This is especially helpful when you have a very large number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(elmo_train_loaded, y_train) # Creating a DMatrix to make XGBoost more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s specify our parameters and set our stopping criteria. For now, let’s be aggressive with the stopping and say we don’t want the accuracy to improve for at least 100 new trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb optimal parameters\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':5, 'min_child_weight':3}\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'],\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at our CV results to see how accurate we were with these settings. The output is automatically saved into a *Pandas* dataframe for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best iteration: 210**. Our CV test error at this number of iterations is 8.4%, or **91.6% accuracy**.\n",
    "\n",
    "Now that we have our best settings, let’s create this as an *XGBoost* object model that we can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':5, 'min_child_weight':3}\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now save the trained model as a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_gb,open(\"ELMO_nlp_xgboost.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Performance on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct a test dataset to analyze the performance of our trained model, and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space'] # Extracting two specific categories\n",
    "idx=0\n",
    "cnt=0\n",
    "with open(\"ELMo_input_data.csv\",\"w\",newline='') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['id','comment_text','label']) # each comment will have an id and a label ('0' or '1')\n",
    "    \n",
    "    for cat in categories:\n",
    "        test= fetch_20newsgroups(subset='test', categories=[cat], remove=('headers', 'footers', 'quotes'))\n",
    "        \n",
    "        for n in range(len(test.data)):            \n",
    "            comment = test.data[n].replace('\\n',\" \")            \n",
    "            # remove URL's from train and test\n",
    "            comment = re.sub(r'http\\S+', '', comment)\n",
    "            # remove punctuation marks\n",
    "            punctuation = '!\"#$%&()*+-/,:;<=>?@[\\\\]^_`{|}~'\n",
    "            comment = ''.join(ch for ch in comment if ch not in set(punctuation))\n",
    "            # convert text to lowercase\n",
    "            comment = comment.lower()\n",
    "            # remove numbers\n",
    "            comment = re.sub(r'[0-9]+', '', comment)\n",
    "            # remove whitespaces\n",
    "            comment = ' '.join(comment.split())\n",
    "\n",
    "            if len(comment)<2000 and len(comment)>25: # discarding very short comments and very large comments\n",
    "                cnt=cnt+1\n",
    "                row = [str(cnt), comment, str(idx)]\n",
    "                w.writerow(row)\n",
    "        idx=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "# Open the CSV\n",
    "f = open('ELMo_input_data.csv', 'r')\n",
    "reader = csv.DictReader(f, fieldnames = ('id','comment_text','label'))  \n",
    "# Parse the CSV into JSON  \n",
    "out = json.dumps([ row for row in reader ])  \n",
    "\n",
    "# Save the JSON  \n",
    "f = open('ELMo_input_data.json', 'w')  \n",
    "f.write(out)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text id label\n",
      "1  some big deletions another in a string of idio...  1     0\n",
      "2  you should wear your nicest boxer shorts and b...  2     0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(617, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_json('ELMo_input_data.json',orient='records')\n",
    "test = test.iloc[1:]\n",
    "print(test.head(2))\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate *ELMo* vectors for test data, and save them in a *.pickle* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_samples = 1 # set to 1 to score all of input dataset  \n",
    "batch_size = 50\n",
    "list_test = [test[i:i+batch_size] for i in range(0,floor(percent_samples*test.shape[0]),batch_size)]\n",
    "\n",
    "# Extract ELMo embeddings - Uncomment the two lines below to compute from scartch; otherwise, load from .pcikle file\n",
    "# elmo_vecs = [elmo_vectors(x['comment_text']) for x in list_test]\n",
    "# elmo_vecs = np.concatenate(elmo_vecs, axis = 0)\n",
    "\n",
    "# save elmo_vecs\n",
    "pickle_out = open(\"elmo_test.pickle\",\"wb\")\n",
    "pickle.dump(elmo_vecs, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we've previously saved elmo_vecs in a .pickle file, we can simply load them\n",
    "pickle_in = open(\"elmo_test_1.pickle\", \"rb\")\n",
    "elmo_vecs = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the trained *XGBoost* model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "loaded_model = pickle.load(open(\"ELMo_nlp_xgboost.pickle\",\"rb\")) # load saved xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(loaded_model.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate predictions on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(xgb.DMatrix(elmo_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.87347245e-01 7.31116712e-01 3.28189023e-02 2.58683780e-04\n",
      " 6.39936002e-03 7.10943580e-01 2.15560973e-01 6.60109101e-03\n",
      " 4.70442843e-04 9.96160150e-01 8.58237094e-04 1.93643868e-01\n",
      " 2.04130150e-02 1.43510429e-03 4.26262530e-04 2.59525259e-03\n",
      " 1.42872185e-01 9.98519480e-01 2.19664257e-02 6.64148748e-01\n",
      " 1.38154048e-02 1.53272906e-02 1.21697402e-02 4.27198305e-04\n",
      " 2.21942384e-02 9.52323496e-01 8.99149978e-04 1.43053591e-01\n",
      " 4.64153141e-02 2.97685619e-03 2.06443062e-03 1.40017986e-01\n",
      " 6.57744527e-01 1.47331674e-02 1.39694829e-02 5.53940004e-03\n",
      " 7.73854554e-01 1.45339807e-02 1.32592511e-03 9.90438044e-01\n",
      " 6.48238584e-02 9.98781741e-01 5.94218553e-04 1.05184328e-03\n",
      " 2.77987301e-01 9.10708010e-01 7.50156343e-01 4.10835678e-03\n",
      " 6.78646611e-04 9.36977923e-01 6.52891397e-03 1.23848999e-03\n",
      " 3.05006057e-01 8.78522933e-01 3.61156076e-01 5.01230417e-04\n",
      " 9.31613445e-01 1.56352371e-02 7.54740788e-04 6.94161560e-03\n",
      " 4.38514277e-02 9.81914927e-05 7.04622790e-02 6.76127244e-03\n",
      " 6.34107709e-01 5.34928637e-04 7.50632465e-01 9.07947589e-03\n",
      " 2.59287399e-03 1.92109356e-03 2.90725613e-03 2.16573834e-01\n",
      " 1.30007127e-02 7.84325821e-04 1.42261311e-02 2.82142009e-03\n",
      " 1.05879339e-03 3.15323565e-03 4.29021269e-01 4.76186920e-04\n",
      " 5.96816003e-01 2.34203460e-03 1.38631475e-03 8.01181979e-03\n",
      " 9.67525423e-01 4.48251545e-01 1.75806461e-03 1.64856955e-01\n",
      " 2.21112801e-04 7.56029272e-04 1.09126724e-01 1.25009669e-02\n",
      " 5.74626088e-01 4.34783064e-02 1.49947929e-03 9.47923243e-01\n",
      " 7.15759993e-01 6.98728919e-01 2.55531305e-03 5.94934300e-02\n",
      " 1.91739120e-04 6.22785330e-01 1.37547567e-03 1.27513369e-03\n",
      " 9.62132365e-02 1.93591081e-02 7.68056989e-01 2.75675729e-02\n",
      " 9.96225119e-01 1.38094139e-04 1.84696796e-03 9.01778877e-01\n",
      " 1.47390455e-01 1.20651617e-03 8.64694476e-01 2.86930386e-04\n",
      " 2.77460814e-01 1.82314992e-01 7.19890833e-01 1.80546343e-02\n",
      " 1.97228100e-02 1.02084555e-01 6.46178750e-03 3.34483944e-03\n",
      " 8.51910293e-01 1.64678332e-03 1.87512045e-03 2.56411405e-03\n",
      " 7.72232830e-04 8.78124118e-01 4.01533878e-04 3.62708755e-02\n",
      " 1.19907199e-03 1.08745499e-02 6.16534206e-04 5.31942584e-02\n",
      " 5.16188389e-04 6.68508589e-01 1.42450689e-03 7.51305640e-01\n",
      " 1.45981100e-03 1.42514601e-03 8.44558293e-04 1.16697341e-01\n",
      " 1.23138120e-03 2.70715561e-02 1.75059903e-02 6.14240646e-01\n",
      " 9.95437443e-01 3.02174082e-03 1.15864381e-01 7.62314379e-01\n",
      " 6.31645560e-01 6.73371375e-01 6.48740113e-01 8.72068584e-01\n",
      " 6.81472346e-02 2.87600327e-03 9.06382084e-01 6.93063857e-03\n",
      " 5.41064795e-03 4.72218206e-04 1.21267267e-01 2.04833671e-01\n",
      " 7.01461494e-01 2.47417513e-04 1.78051833e-03 2.65345089e-02\n",
      " 1.98815927e-01 7.91408658e-01 8.17026198e-01 7.66803743e-03\n",
      " 2.29687011e-03 1.60548817e-02 8.03157091e-01 1.58909082e-01\n",
      " 6.95127249e-01 3.72563303e-02 2.40527555e-01 2.32143953e-01\n",
      " 3.64770651e-01 6.80407160e-04 3.81530775e-03 9.23195155e-04\n",
      " 6.28498018e-01 2.23634318e-01 3.96927983e-01 5.40168047e-01\n",
      " 6.35174960e-02 9.11898836e-02 4.60085601e-01 8.03542137e-01\n",
      " 6.51328417e-04 1.53971957e-02 3.09133716e-02 5.56190252e-01\n",
      " 8.09404068e-03 2.36523211e-01 3.28382244e-03 2.21973836e-01\n",
      " 9.49031580e-03 2.65109241e-02 7.47539043e-01 1.55343086e-01\n",
      " 1.29741419e-03 9.88754153e-01 1.18763428e-02 1.65739376e-02\n",
      " 1.35884866e-01 7.08853781e-01 7.74439191e-04 2.44631781e-04\n",
      " 3.57086025e-02 7.99538568e-02 4.08710152e-01 9.75758943e-04\n",
      " 6.63334727e-01 8.75003636e-04 6.82441401e-04 7.68671110e-02\n",
      " 9.66169119e-01 2.84860224e-01 3.01933259e-01 7.82916546e-01\n",
      " 1.18215838e-02 7.31768757e-02 1.39541492e-01 9.65246618e-01\n",
      " 1.38919458e-01 4.54715073e-01 3.46518331e-03 1.65001489e-02\n",
      " 2.19768509e-01 6.57058775e-01 4.89643635e-03 6.63195970e-04\n",
      " 9.34026301e-01 9.03362870e-01 1.14928198e-03 3.74024987e-01\n",
      " 2.18939711e-03 3.34332144e-04 9.24418330e-01 3.85653153e-02\n",
      " 4.37582880e-01 7.41937995e-01 2.31341749e-01 5.39533645e-02\n",
      " 5.43785580e-02 7.79419899e-01 9.78166163e-01 8.09418678e-01\n",
      " 1.73133090e-01 6.65394247e-01 7.52722800e-01 5.61299585e-02\n",
      " 9.22204673e-01 1.24354199e-01 6.23848615e-03 1.32200848e-02\n",
      " 2.32049823e-03 9.69739020e-01 6.27845466e-01 2.14901250e-02\n",
      " 2.09802017e-03 3.77232966e-04 3.36324364e-01 2.03736578e-04\n",
      " 5.38967192e-01 7.96465933e-01 8.68318617e-01 9.99144077e-01\n",
      " 8.59702229e-01 9.99423862e-01 9.99777853e-01 9.98417616e-01\n",
      " 2.20365133e-02 9.99185622e-01 9.99787867e-01 9.99577820e-01\n",
      " 9.99912739e-01 9.97119308e-01 9.99246478e-01 7.65021741e-01\n",
      " 9.99288797e-01 9.94918108e-01 9.99961019e-01 9.99656081e-01\n",
      " 8.57378364e-01 9.79662955e-01 9.85311747e-01 9.96963322e-01\n",
      " 9.96821284e-01 9.99885082e-01 9.99826014e-01 8.68898153e-01\n",
      " 1.45406097e-01 9.99233961e-01 9.99812305e-01 9.91006911e-01\n",
      " 9.64430213e-01 9.96529639e-01 9.99419093e-01 9.99492407e-01\n",
      " 9.98154938e-01 9.99432981e-01 3.54645163e-01 9.98828709e-01\n",
      " 9.96408045e-01 9.92715180e-01 9.60734069e-01 9.99592364e-01\n",
      " 9.99886394e-01 9.99849677e-01 9.99171019e-01 7.99809515e-01\n",
      " 9.88966167e-01 8.25808663e-03 9.37460661e-01 9.98774588e-01\n",
      " 9.84487116e-01 9.96709943e-01 9.86123800e-01 9.99483585e-01\n",
      " 6.76958442e-01 9.98628497e-01 9.99482751e-01 9.99530196e-01\n",
      " 9.26286578e-01 9.95963573e-01 8.82130980e-01 9.99072790e-01\n",
      " 9.97702301e-01 9.99576747e-01 9.99655366e-01 9.93370652e-01\n",
      " 9.89792466e-01 9.62894320e-01 9.97876883e-01 9.99880552e-01\n",
      " 5.10589957e-01 9.93971109e-01 8.74090612e-01 9.99736726e-01\n",
      " 9.99465406e-01 9.89032328e-01 9.96115923e-01 9.92948174e-01\n",
      " 9.99911070e-01 9.25478280e-01 9.88932490e-01 8.66061270e-01\n",
      " 9.98714447e-01 9.14341033e-01 9.99564588e-01 9.69538629e-01\n",
      " 9.57544208e-01 9.99005497e-01 9.99947548e-01 9.84341323e-01\n",
      " 2.66450763e-01 6.11117661e-01 9.99780476e-01 9.13798213e-01\n",
      " 4.86414552e-01 9.98126924e-01 9.98508871e-01 8.11901987e-01\n",
      " 9.98415112e-01 7.00512230e-01 9.95323718e-01 9.98502016e-01\n",
      " 9.99826849e-01 9.63278651e-01 9.00275528e-01 9.98456001e-01\n",
      " 9.99191344e-01 9.23982203e-01 2.60957778e-01 9.91939604e-01\n",
      " 9.99507308e-01 3.68899316e-01 9.94896829e-01 9.78821039e-01\n",
      " 9.95941162e-01 9.89402771e-01 9.94304717e-01 9.99357641e-01\n",
      " 9.81926978e-01 5.83419561e-01 9.96883214e-01 9.93259490e-01\n",
      " 9.99597609e-01 9.98754740e-01 9.73488510e-01 9.97699797e-01\n",
      " 3.29256177e-01 9.96075213e-01 9.91732359e-01 9.97979105e-01\n",
      " 4.01589125e-02 9.91040170e-01 9.99584734e-01 9.99493837e-01\n",
      " 8.51296544e-01 9.97321308e-01 9.99148607e-01 7.92180657e-01\n",
      " 9.98906374e-01 9.99482751e-01 9.94554639e-01 9.91070390e-01\n",
      " 9.99523997e-01 9.98365700e-01 8.85961235e-01 9.60279584e-01\n",
      " 9.99795139e-01 9.95296061e-01 1.76959127e-01 9.26929176e-01\n",
      " 9.58010912e-01 9.97115254e-01 6.81516588e-01 9.83613849e-01\n",
      " 9.99482751e-01 9.67816651e-01 9.04303014e-01 9.98905182e-01\n",
      " 9.59455311e-01 9.79406655e-01 9.93797362e-01 9.94909704e-01\n",
      " 5.36821008e-01 9.94049072e-01 2.08911207e-02 9.99924660e-01\n",
      " 9.99818027e-01 1.95421562e-01 9.99835491e-01 9.97216940e-01\n",
      " 8.76106620e-01 9.99109209e-01 9.87217724e-01 9.98683631e-01\n",
      " 9.89672780e-01 9.99854088e-01 9.99851584e-01 9.48255241e-01\n",
      " 9.99704182e-01 9.98314857e-01 9.97805655e-01 9.91403818e-01\n",
      " 9.99168634e-01 9.99632359e-01 9.99640703e-01 9.53859866e-01\n",
      " 9.72499311e-01 9.95269835e-01 9.59457636e-01 7.26690233e-01\n",
      " 9.99111235e-01 9.49404716e-01 9.09678042e-01 9.97493982e-01\n",
      " 9.93825555e-01 8.86492133e-01 9.99813616e-01 9.84200180e-01\n",
      " 8.77933502e-01 9.92302775e-01 9.99460638e-01 9.98425603e-01\n",
      " 9.99741256e-01 9.79440808e-01 7.14057922e-01 9.97027814e-01\n",
      " 9.98142242e-01 9.99093533e-01 9.74945903e-01 9.30981219e-01\n",
      " 9.99112308e-01 8.73192430e-01 9.99622226e-01 9.57298219e-01\n",
      " 9.89579499e-01 9.76434231e-01 9.98916984e-01 8.92433226e-01\n",
      " 9.98518765e-01 9.99766052e-01 7.88236320e-01 9.15131509e-01\n",
      " 9.99891043e-01 9.99761164e-01 2.57010341e-01 9.99813855e-01\n",
      " 9.95792627e-01 9.97263312e-01 9.97123897e-01 9.99789178e-01\n",
      " 9.99357164e-01 9.99921918e-01 9.50088382e-01 9.99263346e-01\n",
      " 9.75878060e-01 9.85131919e-01 8.63673091e-01 9.99618649e-01\n",
      " 9.99368250e-01 9.99842048e-01 9.61035430e-01 9.99813616e-01\n",
      " 9.99578536e-01 5.04348814e-01 1.01995751e-01 9.98555958e-01\n",
      " 9.99652863e-01 9.98261273e-01 9.97185767e-01 9.99445736e-01\n",
      " 9.98472989e-01 9.99659538e-01 9.97578561e-01 8.58578563e-01\n",
      " 9.96960461e-01 9.99487400e-01 9.99895930e-01 9.84317660e-01\n",
      " 9.92648423e-01 9.62218702e-01 9.95143771e-01 9.99846101e-01\n",
      " 9.76132333e-01 9.95135486e-01 9.99875188e-01 6.11768067e-01\n",
      " 9.99938965e-01 2.08400816e-01 9.88402784e-01 7.54612148e-01\n",
      " 8.75007749e-01 9.99682784e-01 9.99943495e-01 9.99279320e-01\n",
      " 9.98595297e-01 9.95650470e-01 9.46175039e-01 9.99718368e-01\n",
      " 9.25828516e-01 7.23192513e-01 9.56225216e-01 9.14678693e-01\n",
      " 9.99308348e-01 9.99224305e-01 9.96078312e-01 9.99597967e-01\n",
      " 9.99769151e-01 9.99814212e-01 1.80197379e-03 9.93001997e-01\n",
      " 9.99414206e-01 4.64765072e-01 9.99157310e-01 9.99904871e-01\n",
      " 9.75989699e-01 5.47342360e-01 9.99700308e-01 8.63931239e-01\n",
      " 9.90436494e-01 9.98468578e-01 9.98199821e-01 9.99494433e-01\n",
      " 9.98381853e-01 9.67676640e-01 9.98958111e-01 9.89622116e-01\n",
      " 9.99684334e-01 9.91378665e-01 9.99855161e-01 9.99768436e-01\n",
      " 9.85122979e-01 9.85139191e-01 9.99657273e-01 9.87964869e-01\n",
      " 3.18108052e-02 3.73726040e-02 9.99652863e-01 9.99863625e-01\n",
      " 9.99867439e-01 9.98518646e-01 4.15593803e-01 8.82728815e-01\n",
      " 9.97274697e-01 9.96160269e-01 9.88395810e-01 9.99069631e-01\n",
      " 9.99834538e-01 9.79826570e-01 1.81164116e-01 6.01575673e-01\n",
      " 9.99451578e-01 9.97632027e-01 9.77539897e-01 1.04043625e-01\n",
      " 9.81837332e-01 9.98540163e-01 9.99827981e-01 6.99670836e-02\n",
      " 9.99905944e-01 9.99601424e-01 6.21941984e-01 9.99428689e-01\n",
      " 9.98211861e-01 9.53314960e-01 9.84658360e-01 9.99228716e-01\n",
      " 9.94014204e-01]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use *sklearn*’s accuracy metric to see how well we did on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function for *XGBoost* outputs probabilities by default and not actual class labels. To calculate accuracy we need to convert these to a 0/1 label. We will set 0.5 probability as our threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  84.12 %\n"
     ]
    }
   ],
   "source": [
    "y_test = test['label']\n",
    "temp = np.array(y_test)\n",
    "y_test = temp.astype(np.int) # converting y_train to integers\n",
    "\n",
    "print(\"Accuracy on test data: \",round(100*accuracy_score(predictions, y_test),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying to FastScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we import the *fastscoredeploy* library. This will leverage the FastScore API for deploying assets and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastscoredeploy import ipmagic\n",
    "from fastscore.io import Slot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemas are going to define the input and output contract of the model execution code with the data transport. We will add one  for input and another output. Schemas leverage the Avro system: https://avro.apache.org/docs/1.8.1/spec.html. The cell magic command **%%schema (name)** at the top defines the name of the schema. \n",
    "\n",
    "**Note**: the name in this command must match the name of the corresponding schema name in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema loaded and bound to three_strings variable\n"
     ]
    }
   ],
   "source": [
    "%%schema three_strings\n",
    "{\n",
    "    \"items\": {\n",
    "        \"fields\": [\n",
    "            {   \"name\": \"label\",        \"type\": \"string\"   },\n",
    "            {   \"name\": \"comment_text\", \"type\": \"string\"   },\n",
    "            {   \"name\": \"id\",           \"type\": \"string\"   }\n",
    "        ],\n",
    "        \"name\": \"three_strings\",\n",
    "        \"type\": \"record\"\n",
    "    },\n",
    "    \"type\": \"array\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema loaded and bound to double variable\n"
     ]
    }
   ],
   "source": [
    "%%schema double\n",
    "{\"type\":\"double\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemata can also be inferred from sample data using **Schema.infer**. The samples must be given as records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastscoredeploy.Schema import infer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = dict({\"id\":\"5\", \"comment_text\":\"Oh my God\", \"label\":\"0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5', 'comment_text': 'Oh my God', 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(input_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"record\",\n",
      "    \"name\": \"Rec476098\",\n",
      "    \"fields\": [\n",
      "        {\n",
      "            \"name\": \"label\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"comment_text\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"id\",\n",
      "            \"type\": \"string\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(infer([input_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = json.loads(infer([input_sample]))\n",
    "temp = json.dumps(temp,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"three_strings.avsc\",\"w\")\n",
    "f.write(temp)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to provide the model execution code. This code will be deployed into the engine and used to score new data. \n",
    " - The cell magic command **%%model** at the top defines the name of the model *ELMo_nlp*.\n",
    " - We will not be using *FastScore*'s *call-back* style (begin and action functions), so we use the smar comment **#fastscore.action: unused**\n",
    " - The following smart comments map the schemas to the input and output. The names of the schemas in these smart comments must match the names of the schemas in the cell magic commands above (the name after **%%schema**). \n",
    " - Next, use import statements to pull in the dependencies. Since the engine is containerized, you must include these import statements again even though you included them at the beginning of the notebook. These will need to be added to the Fastscore Engine's Dockerfile and import policy if they are not included in the default engine. \n",
    " - Slot(0) and Slot(1) are the default input and output slots, respectively. Data coming to the input stream will be read and processed as a *Pandas DataFrame*. Any data processing that has to be carried  is done before scoring. The trained model is then loaded (from, say a *.pickle* file), and used to assign predictions to input data. these predictions are assigned to the output slot, Slot(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and bound to ELMo_nlp variable.\n"
     ]
    }
   ],
   "source": [
    "%%model ELMo_nlp\n",
    "\n",
    "#fastscore.action: unused\n",
    "#fastscore.schema.0: three_strings\n",
    "#fastscore.schema.1: double\n",
    "#fastscore.recordsets.1: true\n",
    "#fastscore.module-attached: tensorflow\n",
    "#fastscore.module-attached: tensorflow_hub\n",
    "#fastscore.module-attached: xgboost\n",
    "\n",
    "from fastscore.io import Slot\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "\n",
    "slot0 = Slot(0)\n",
    "slot1 = Slot(1)\n",
    "\n",
    "   \n",
    "#print(tf.__version__)\n",
    "\n",
    "input_data = slot0.read(format=\"pandas.standard\")\n",
    "input_data = input_data.iloc[0:]\n",
    "\n",
    "#print(\"input_data  type: \", type(input_data))\n",
    "#print(\"input_data shape: \", input_data.shape)\n",
    "#print(input_data.head())\n",
    "\n",
    "percent_samples = 1 # set to 1 to score all of input dataset\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "temp = input_data.shape[0]\n",
    "\n",
    "#print([[1,2] for i in range(0,floor(percent_samples*temp),batch_size)])\n",
    "\n",
    "list_input_data = []\n",
    "\n",
    "for i in range(0,floor(percent_samples*temp),batch_size):\n",
    "    list_input_data+=[input_data[i:i+batch_size]]\n",
    "\n",
    "#print(list_input_data)\n",
    "\n",
    "#list_input_data = [input_data[i:i+batch_size] for i in range(0,floor(percent_samples*temp),batch_size)]\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "globals().update(locals())\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        # sess.run(tf.tables_initializer())\n",
    "        sess.run(tf.compat.v1.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))\n",
    "\n",
    "\n",
    "# Extract ELMo embeddings\n",
    "globals().update(locals())\n",
    "elmo_vecs = [elmo_vectors(x['comment_text']) for x in list_input_data]\n",
    "\n",
    "'''elmo_vecs = []\n",
    "\n",
    "for x in list_input_data:\n",
    "    elmo_vecs += [[elmo_vectors(x['comment_text'])]]'''\n",
    "\n",
    "elmo_vecs = np.concatenate(elmo_vecs, axis = 0)\n",
    "\n",
    "loaded_model = pickle.load(open(\"ELMo_nlp_xgboost.pickle\",\"rb\"))\n",
    "\n",
    "predictions = loaded_model.predict(xgb.DMatrix(elmo_vecs))\n",
    "\n",
    "out = pd.Series(predictions)\n",
    "\n",
    "slot1.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrive your model's source code, uncomment the line below\n",
    "# print(ELMo_nlp.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the model is working as expected, we can pass sample data to the *scoreExplicit* function.\n",
    "\n",
    "**NOTE**: <code>input_data = slot0.read(format=\"pandas.standard\")</code> should be changed to <code>input_data = slot0.read(format=\"pandas\")</code> for *scoreExplicit* to run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input: \n",
      "\n",
      "   comment_text id label\n",
      "0    Oh my God  5     0\n",
      "\n",
      "Sample score:\n",
      "\n",
      "[<PandasArray>\n",
      "[0.6168823]\n",
      "Length: 1, dtype: float32]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample input: \\n\\n\", pd.DataFrame([input_sample]).head())\n",
    "\n",
    "ELMo_nlp.scoreExplicit(pd.DataFrame([input_sample]))\n",
    "out = Slot(1).output()\n",
    "print(\"\\nSample score:\\n\")\n",
    "print(out)\n",
    "print(type(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to deploy our FastScore-conformed model to a FastScore engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Connect:  connect\n",
      "Model Manage:  model-manage-1\n",
      "      Engine:  engine-1\n"
     ]
    }
   ],
   "source": [
    "#Let us now deploy the model to FastScore to validate it works within the Engine\n",
    "from fastscoredeploy.suite import Connect\n",
    "\n",
    "connect = Connect(\"https://ec2-18-223-205-88.us-east-2.compute.amazonaws.com:8000\")\n",
    "print(\"     Connect: \",connect.name)\n",
    "\n",
    "#Then we specify the model-manage to add the model assets to:\n",
    "model_manage = connect.lookup('model-manage')\n",
    "print(\"Model Manage: \",model_manage.name)\n",
    "\n",
    "#And finally we specify the Engine we will deploy to\n",
    "connect.prefer('engine','engine-1')\n",
    "eng = connect.lookup('engine')\n",
    "print(\"      Engine: \", eng.name)\n",
    "\n",
    "# To check current configuration, uncomment the line below\n",
    "# print(\"\\n\",connect.get_config())\n",
    "\n",
    "# To check current fleet info, uncomment the line below\n",
    "# print(\"\\n\",connect.fleet())\n",
    "\n",
    "# To retrieve pneumo messages, uncomment the lines below\n",
    "# pneumo = connect.pneumo.socket()\n",
    "# print(pneumo.recv())\n",
    "# pneumo.close()\n",
    "\n",
    "# To retrieve the Swagger specification of the API supported by the instance, uncomment the lines below\n",
    "# print(connect.get_swagger())\n",
    "\n",
    "# To retrieves version information from the instance, uncomment the line below. A successful reply means instance is healthy.\n",
    "# connect.check_health()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = three_strings.verify(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(eng.verify_data(sid,mydf.to_dict(orient='records')[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     connect is:  <fastscoredeploy.suite.Connect.Connect object at 0x00000000354E22E8>\n",
      "        eng  is:  <fastscoredeploy.suite.Engine.Engine object at 0x000000000F986588>\n",
      "model_manage is:  <fastscoredeploy.suite.ModelManage.ModelManage object at 0x00000000398FC128>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n     connect is: \",connect)\n",
    "print(\"        eng  is: \",  eng)\n",
    "print(\"model_manage is: \",  model_manage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyting looks <span style=\"color:green\"><b>good</b></span>! Let's update Model Manage with our ELMo_nlp model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELMo_nlp.update(model_manage=model_manage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Models in Model Manage:  ['ELMo_nlp']\n",
      "\n",
      "Schemata in Model Manage:  ['three_strings', 'double']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n  Models in Model Manage: \",model_manage.models.names())\n",
    "print(\"\")\n",
    "print(\"Schemata in Model Manage: \",  model_manage.schemata.names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we upload to the model (ELMo_nlp) the trained **XGBoost** model (ELMo_nlp_xgboost), which will be used to give ppredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastscore.attachment import Attachment\n",
    "\n",
    "att = Attachment('ELMo_nlp_xgboost.tar.gz', datafile='ELMo_nlp_xgboost.tar.gz')\n",
    "att.upload(ELMo_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ea790f67a7418ebc5bd4e1d3bf4e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we deploy to the engine. Start by resetting the engine in case it had previously errored.\n",
    "eng.reset()\n",
    "\n",
    "# Deploy! If there are errors, view the container logs for details\n",
    "ELMo_nlp.deploy(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Engine is:  RUNNING\n",
      "\n",
      "Active model name:  ELMo_nlp\n",
      "Active model type:  python3\n"
     ]
    }
   ],
   "source": [
    "# To ckeck the engine state\n",
    "print(\"The Engine is: \",eng.state)\n",
    "\n",
    "# To check active model name and type\n",
    "print(\"\\nActive model name: \",eng.active_model.name)\n",
    "print(\"Active model type: \",  eng.active_model.mtype)\n",
    "# print(engine.active_model.jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model attachments:  ['ELMo_nlp_xgboost.tar.gz']\n"
     ]
    }
   ],
   "source": [
    "print(\"Model attachments: \",ELMo_nlp.attachments.names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = pd.DataFrame({\"id\":[\"5\",\"6\"], \"comment_text\":[\"Oh my God\",\"Space is cool\"], \"label\":[\"0\",\"1\"]})\n",
    "\n",
    "type(mydf.to_dict(orient='records')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of  [mydf.to_dict(orient='records')[0:2] :  <class 'list'>\n",
      "Type of [[mydf.to_dict(orient='records')[0:2]]:  <class 'list'>\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', OSError(\"(10053, 'WSAECONNABORTED')\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZeroReturnError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: (10053, 'WSAECONNABORTED')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    640\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 641\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    642\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZeroReturnError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', OSError(\"(10053, 'WSAECONNABORTED')\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-515-a8e08b61bb50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Type of [[mydf.to_dict(orient='records')[0:2]]: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmydf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0meng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmydf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sami\\desktop\\model-deploy\\fastscore-model-deploy-master\\fastscore-model-deploy-master\\fastscoredeploy\\python\\build\\lib\\fastscoredeploy\\suite\\Engine.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, data, encode)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# returns bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# returns bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\fastscore\\suite\\engine.py\u001b[0m in \u001b[0;36moutput\u001b[1;34m(self, slot)\u001b[0m\n\u001b[0;32m    194\u001b[0m         }\n\u001b[0;32m    195\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{host}/{instance}/1/job/output/{slot}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', OSError(\"(10053, 'WSAECONNABORTED')\"))"
     ]
    }
   ],
   "source": [
    "#Now we score with our sample data\n",
    "\n",
    "print(\"Type of  [mydf.to_dict(orient='records')[0:2] : \", type([mydf.to_dict(orient='records')[0:2]]))\n",
    "print(\"Type of [[mydf.to_dict(orient='records')[0:2]]: \", type([[mydf.to_dict(orient='records')[0:2]]]))\n",
    "\n",
    "eng.score([mydf.to_dict(orient='records')[0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {
    "c0cd3384c6df4977b68c5a4ad6ee757d": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
